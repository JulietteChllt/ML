{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "import implementations as imp\n",
    "%run pre_processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../resources/train.csv'\n",
    "test_path = '../resources/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tx_1,y_1,ids_1), (tx_2,y_2,ids_2), (tx_3,y_3,ids_3),indexes,parameters = process_data(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-323e41850264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mxtest_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mids_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxtest_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mids_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxtest_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mids_3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-6d71fc3efb9f>\u001b[0m in \u001b[0;36mprocess_test\u001b[0;34m(path, indexes, parameters)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mskewed2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mskewed3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdata_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_transform_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskewed1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mdata_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_transform_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskewed2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdata_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_transform_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskewed3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2b7daca4e8f4>\u001b[0m in \u001b[0;36mscale_transform_test\u001b[0;34m(data_n, parameters, skewed)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mminimum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmaximum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdividor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "(xtest_1,ids_1), (xtest_2,ids_2), (xtest_3,ids_3) = process_test(test_path,indexes,parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y,x,w):\n",
    "    y_pred = predict_labels(w,x)\n",
    "    return (y_pred==y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "def evaluate_stability(y,tx,lambda_,degree):\n",
    "    acc_train = []\n",
    "    acc_test = []  \n",
    "    k_fold = 5\n",
    "\n",
    "    for i in range (40):\n",
    "        seed = randint(1, 40)\n",
    "        k_indices = build_k_indices(y, k_fold, seed)\n",
    "        #(ltr,lte,acctr,accte) = cross_validation_lsgd(y, tx, k_indices, k_fold, degree)\n",
    "        #(ltr,lte,acctr,accte) = cross_validation_ls_sgd(y, tx, k_indices, k_fold, degree)\n",
    "        #(ltr,lte,acctr,accte) = cross_validation_rg(y, tx, k_indices, k_fold, lambda_, degree)\n",
    "        (ltr,lte,acctr,accte) = cross_validation_ls(y, tx, k_indices, k_fold, degree)\n",
    "        acc_train.append(acctr)\n",
    "        acc_test.append(accte)\n",
    "    \n",
    "    return (np.mean(acc_test),np.std(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters with least squares gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation for least squares gradient descent\n",
    "def cross_validation_lsgd(y, tx, k_indices, k_fold , degree):\n",
    "    gamma = 0.01\n",
    "    max_iters = 100 \n",
    "    loss_te = np.array([])\n",
    "    loss_tr = np.array([])\n",
    "    acc_te = np.array([]) \n",
    "    acc_tr = np.array([]) \n",
    "    #print(x.shape)\n",
    "    for i in range(k_fold):\n",
    "        sub = np.delete(k_indices,i,axis=0).flatten()\n",
    "        x_train = tx[sub]\n",
    "        y_train = y[sub]\n",
    "        x_test = tx[k_indices[i]]\n",
    "        y_test = y[k_indices[i]]\n",
    "        \n",
    "        x_train = expand_with_pairwise_products(x_train,degree)\n",
    "        x_test = expand_with_pairwise_products(x_test,degree)\n",
    "        initial_w = np.zeros((x_train.shape[1], 1))\n",
    "        \n",
    "        #x_train = np.append(x_train,np.cos(x_train),axis=1)\n",
    "        #x_train = np.append(x_train,np.sin(x_train),axis=1)\n",
    "        #x_test = np.append(x_test,np.cos(x_test),axis=1)\n",
    "        #x_test = np.append(x_test,np.sin(x_test),axis=1)\n",
    "\n",
    "        w,loss_train = imp.least_squares_GD(y_train, x_train,initial_w, max_iters, gamma)\n",
    "        acc_train = compute_accuracy(y_train,x_train,w)\n",
    "        acc_test = compute_accuracy(y_test,x_test,w)\n",
    "        loss_test = imp.compute_loss(y_test, x_test, w)\n",
    "        loss_tr = np.append(loss_tr,loss_train)\n",
    "        loss_te= np.append(loss_te,loss_test)\n",
    "        acc_tr = np.append(acc_tr,acc_train)\n",
    "        acc_te = np.append(acc_te,acc_test)\n",
    "    \n",
    "    return np.mean(loss_tr),np.mean(loss_te),np.mean(acc_tr), np.mean(acc_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for deg  0  : mean acc =  0.6160954859373436  std acc =  0.0006841755578733185\n",
      "for deg  1  : mean acc =  0.6525573015714143  std acc =  0.0009457797705223383\n",
      "for deg  2  : mean acc =  0.7414057651886699  std acc =  0.0009345877487803651\n",
      "for deg  3  : mean acc =  0.527395155640076  std acc =  0.0026980060191707203\n",
      "for deg  4  : mean acc =  0.646620708637774  std acc =  0.0012159548194315816\n"
     ]
    }
   ],
   "source": [
    "for deg in range (0,5):\n",
    "    meanacc,stdacc = evaluate_stability(y_1,tx_1,1,deg)\n",
    "    print(\"for deg \", deg, \" : mean acc = \", meanacc, \" std acc = \",stdacc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for deg  0  : mean acc =  0.6522062806293526  std acc =  0.00020586874945418152\n",
      "for deg  1  : mean acc =  0.7067745679649213  std acc =  0.00021620897818771918\n",
      "for deg  2  : mean acc =  0.6455722852721177  std acc =  7.70232701151051e-05\n",
      "for deg  3  : mean acc =  0.5367639282950736  std acc =  0.0007092315211750706\n",
      "for deg  4  : mean acc =  0.36630448800619037  std acc =  0.0016245499737238191\n"
     ]
    }
   ],
   "source": [
    "for deg in range (0,5):\n",
    "    meanacc,stdacc = evaluate_stability(y_2,tx_2,1,deg)\n",
    "    print(\"for deg \", deg, \" : mean acc = \", meanacc, \" std acc = \",stdacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for deg  0  : mean acc =  0.6831930658946788  std acc =  0.00029731466788252096\n",
      "for deg  1  : mean acc =  0.7343072787427627  std acc =  0.00029293047221711193\n",
      "for deg  2  : mean acc =  0.7125865039977943  std acc =  0.00026692809489219153\n",
      "for deg  3  : mean acc =  0.5070971188309897  std acc =  0.0004849075744523343\n",
      "for deg  4  : mean acc =  0.4352508960573477  std acc =  0.0006155791997781928\n"
     ]
    }
   ],
   "source": [
    "for deg in range (0,5):\n",
    "    meanacc,stdacc = evaluate_stability(y_3,tx_3,1,deg)\n",
    "    print(\"for deg \", deg, \" : mean acc = \", meanacc, \" std acc = \",stdacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best results for least squares stochastic gradient descent \n",
    "#batch 1 : deg = 2   avg acc = 0.7414057651886699   std acc = 0.0009345877487803651\n",
    "#batch 2 : deg = 1   avg acc = 0.7067745679649213   std acc = 0.00021620897818771918\n",
    "#batch 3 : deg = 1   avg acc = 0.7343072787427627   std acc = 0.00029293047221711193\n",
    "# overall avg acc = 0.7274958706321181   overall std acc = 0.00048124239972839876"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters with least squares stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation for least squares stochastic gradient descent\n",
    "def cross_validation_ls_sgd(y, tx, k_indices, k_fold , degree):\n",
    "    gamma = 0.01\n",
    "    max_iters = 100\n",
    "    batch_size = 100 \n",
    "    loss_te = np.array([])\n",
    "    loss_tr = np.array([])\n",
    "    acc_te = np.array([]) \n",
    "    acc_tr = np.array([]) \n",
    "    #print(x.shape)\n",
    "    for i in range(k_fold):\n",
    "        sub = np.delete(k_indices,i,axis=0).flatten()\n",
    "        x_train = tx[sub]\n",
    "        y_train = y[sub]\n",
    "        x_test = tx[k_indices[i]]\n",
    "        y_test = y[k_indices[i]]\n",
    "        \n",
    "        x_train = expand_with_pairwise_products(x_train,degree)\n",
    "        x_test = expand_with_pairwise_products(x_test,degree)\n",
    "        initial_w = np.zeros((x_train.shape[1], 1))\n",
    "        \n",
    "        #x_train = np.append(x_train,np.cos(x_train),axis=1)\n",
    "        #x_train = np.append(x_train,np.sin(x_train),axis=1)\n",
    "        #x_test = np.append(x_test,np.cos(x_test),axis=1)\n",
    "        #x_test = np.append(x_test,np.sin(x_test),axis=1)\n",
    "\n",
    "        w,loss_train = imp.least_squares_SGD(y_train, x_train,initial_w, batch_size, max_iters, gamma)\n",
    "        acc_train = compute_accuracy(y_train,x_train,w)\n",
    "        acc_test = compute_accuracy(y_test,x_test,w)\n",
    "        loss_test = imp.compute_loss(y_test, x_test, w)\n",
    "        loss_tr = np.append(loss_tr,loss_train)\n",
    "        loss_te= np.append(loss_te,loss_test)\n",
    "        acc_tr = np.append(acc_tr,acc_train)\n",
    "        acc_te = np.append(acc_te,acc_test)\n",
    "    \n",
    "    return np.mean(loss_tr),np.mean(loss_te),np.mean(acc_tr), np.mean(acc_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for deg  0  : mean acc =  0.7366177059353418  std acc =  0.009624198161589994\n",
      "for deg  1  : mean acc =  0.7664277850065059  std acc =  0.015436464620552537\n",
      "for deg  2  : mean acc =  0.736415023521169  std acc =  0.017676041716699516\n",
      "for deg  3  : mean acc =  0.675592533279952  std acc =  0.049554507557525156\n",
      "for deg  4  : mean acc =  0.34157016314683214  std acc =  0.07816910003490728\n"
     ]
    }
   ],
   "source": [
    "for deg in range (0,5):\n",
    "    meanacc,stdacc = evaluate_stability(y_1,tx_1,1,deg)\n",
    "    print(\"for deg \", deg, \" : mean acc = \", meanacc, \" std acc = \",stdacc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for deg  0  : mean acc =  0.6245786045911788  std acc =  0.00999987554396171\n",
      "for deg  1  : mean acc =  0.6658701960278567  std acc =  0.007672366305903255\n",
      "for deg  2  : mean acc =  0.6463834794944545  std acc =  0.006971421873301687\n",
      "for deg  3  : mean acc =  0.5758982460665463  std acc =  0.03041172424468247\n",
      "for deg  4  : mean acc =  0.42116971885478466  std acc =  0.0418602592842612\n"
     ]
    }
   ],
   "source": [
    "for deg in range (0,5):\n",
    "    meanacc,stdacc = evaluate_stability(y_2,tx_2,1,deg)\n",
    "    print(\"for deg \", deg, \" : mean acc = \", meanacc, \" std acc = \",stdacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for deg  0  : mean acc =  0.6095733388475324  std acc =  0.010105285526246196\n",
      "for deg  1  : mean acc =  0.6713802729528536  std acc =  0.007474802933513564\n",
      "for deg  2  : mean acc =  0.676459194926937  std acc =  0.013612359302174318\n",
      "for deg  3  : mean acc =  0.5804545767852219  std acc =  0.020875946264226345\n",
      "for deg  4  : mean acc =  0.4468479459608492  std acc =  0.01794964186827251\n"
     ]
    }
   ],
   "source": [
    "for deg in range (0,5):\n",
    "    meanacc,stdacc = evaluate_stability(y_3,tx_3,1,deg)\n",
    "    print(\"for deg \", deg, \" : mean acc = \", meanacc, \" std acc = \",stdacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best results for least squares stochastic gradient descent \n",
    "#batch 1 : deg = 1   avg acc = 0.7664277850065059   std acc = 0.009624198161589994\n",
    "#batch 2 : deg = 1   avg acc = 0.6658701960278567   std acc = 0.007672366305903255\n",
    "#batch 3 : deg = 2   avg acc = 0.676459194926937    std acc = 0.013612359302174318\n",
    "#overall avc acc = 0.7029190586537665   overall avg std = 0.010302974589889189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters with least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation for least squares\n",
    "def cross_validation_ls(y, x, k_indices, k_fold , degree):\n",
    "    loss_te = np.array([])\n",
    "    loss_tr = np.array([])\n",
    "    acc_te = np.array([]) \n",
    "    acc_tr = np.array([]) \n",
    "    #print(x.shape)\n",
    "    for i in range(k_fold):\n",
    "        sub = np.delete(k_indices,i,axis=0).flatten()\n",
    "        x_train = x[sub]\n",
    "        y_train = y[sub]\n",
    "        x_test = x[k_indices[i]]\n",
    "        y_test = y[k_indices[i]]\n",
    "        \n",
    "        x_train = expand_with_pairwise_products(x_train,degree)\n",
    "        x_test = expand_with_pairwise_products(x_test,degree)\n",
    "        \n",
    "        #x_train = np.append(x_train,np.cos(x_train),axis=1)\n",
    "        #x_train = np.append(x_train,np.sin(x_train),axis=1)\n",
    "        #x_test = np.append(x_test,np.cos(x_test),axis=1)\n",
    "        #x_test = np.append(x_test,np.sin(x_test),axis=1)\n",
    "\n",
    "        w,loss_train = imp.least_squares(y_train, x_train)\n",
    "        acc_train = compute_accuracy(y_train,x_train,w)\n",
    "        acc_test = compute_accuracy(y_test,x_test,w)\n",
    "        loss_test = imp.compute_loss(y_test, x_test, w)\n",
    "        loss_tr = np.append(loss_tr,loss_train)\n",
    "        loss_te= np.append(loss_te,loss_test)\n",
    "        acc_tr = np.append(acc_tr,acc_train)\n",
    "        acc_te = np.append(acc_te,acc_test)\n",
    "    \n",
    "    return np.mean(loss_tr),np.mean(loss_te),np.mean(acc_tr), np.mean(acc_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for deg  0  : mean acc =  0.7957191472325092  std acc =  0.00013912521269141684\n",
      "for deg  1  : mean acc =  0.8323631268141328  std acc =  0.00015279399169057867\n",
      "for deg  2  : mean acc =  0.8337558802922631  std acc =  0.00012203090884993148\n",
      "for deg  3  : mean acc =  0.8357466720048041  std acc =  0.0001682429115639703\n",
      "for deg  4  : mean acc =  0.8387889100190172  std acc =  0.00014135044294997072\n",
      "for deg  5  : mean acc =  0.8409643679311379  std acc =  0.00013730502370455237\n",
      "for deg  6  : mean acc =  0.8381423280952858  std acc =  0.014848742056491664\n",
      "for deg  7  : mean acc =  0.8398308477629867  std acc =  0.011566748377691465\n",
      "for deg  8  : mean acc =  0.8450440396356722  std acc =  0.0003718353247391593\n",
      "for deg  9  : mean acc =  0.8415108597737964  std acc =  0.009320020138757627\n",
      "for deg  10  : mean acc =  0.8441447302572316  std acc =  0.002260838641793926\n",
      "for deg  11  : mean acc =  0.7880307276548894  std acc =  0.03329041646415769\n",
      "for deg  12  : mean acc =  0.7738524672204984  std acc =  0.04199541823516789\n",
      "for deg  13  : mean acc =  0.6960139125212692  std acc =  0.04567342937541805\n"
     ]
    }
   ],
   "source": [
    "for deg in range (0,14):\n",
    "    meanacc,stdacc = evalutate_stability(y_1,tx_1,1,deg)\n",
    "    print(\"for deg \", deg, \" : mean acc = \", meanacc, \" std acc = \",stdacc)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for deg  0  : mean acc =  0.6699277792107299  std acc =  0.0004526787753867319\n",
      "for deg  1  : mean acc =  0.7513373742584474  std acc =  0.0003422599879055013\n",
      "for deg  2  : mean acc =  0.7724258447253033  std acc =  0.00018265385494497166\n",
      "for deg  3  : mean acc =  0.77662883672943  std acc =  0.00028023269240217346\n",
      "for deg  4  : mean acc =  0.7841842919783337  std acc =  0.00020583163317026163\n",
      "for deg  5  : mean acc =  0.7855384317771474  std acc =  0.0002391357508320971\n",
      "for deg  6  : mean acc =  0.7866397988135156  std acc =  0.00029886878150629776\n",
      "for deg  7  : mean acc =  0.7933460149600207  std acc =  0.0002643474316164753\n",
      "for deg  8  : mean acc =  0.8006686871292235  std acc =  0.00024931690743162536\n",
      "for deg  9  : mean acc =  0.8040624193964406  std acc =  0.0001953734512193018\n",
      "for deg  10  : mean acc =  0.8041726850657724  std acc =  0.00020360554846343565\n",
      "for deg  11  : mean acc =  0.8047517410368842  std acc =  0.00029961911925489556\n",
      "for deg  12  : mean acc =  0.8062819190095436  std acc =  0.00014765868113824493\n",
      "for deg  13  : mean acc =  0.7957357492906887  std acc =  0.02281630676212466\n"
     ]
    }
   ],
   "source": [
    "for deg in range (0,14):\n",
    "    meanacc,stdacc = evalutate_stability(y_2,tx_2,1,deg)\n",
    "    print(\"for deg \", deg, \" : mean acc = \", meanacc, \" std acc = \",stdacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for deg  0  : mean acc =  0.7311421284808381  std acc =  0.0004536973572947324\n",
      "for deg  1  : mean acc =  0.7868341604631928  std acc =  0.0003002731708084146\n",
      "for deg  2  : mean acc =  0.7914826302729528  std acc =  0.00041324946611870876\n",
      "for deg  3  : mean acc =  0.8055459057071961  std acc =  0.0003395852461630336\n",
      "for deg  4  : mean acc =  0.8128522194651226  std acc =  0.0003254983411505178\n",
      "for deg  5  : mean acc =  0.8147077474496831  std acc =  0.00031769216976191905\n",
      "for deg  6  : mean acc =  0.8159043286462643  std acc =  0.0003650190492085563\n",
      "for deg  7  : mean acc =  0.8233478081058724  std acc =  0.00033807580422777153\n",
      "for deg  8  : mean acc =  0.8324965536255858  std acc =  0.00026080106775609464\n",
      "for deg  9  : mean acc =  0.8359753239591949  std acc =  0.00030998293922770574\n",
      "for deg  10  : mean acc =  0.8360366694237662  std acc =  0.0003029957051469666\n",
      "for deg  11  : mean acc =  0.8368927488282327  std acc =  0.00038824229970597744\n",
      "for deg  12  : mean acc =  0.8343148607664738  std acc =  0.009791875569386417\n",
      "for deg  13  : mean acc =  0.8286807278742764  std acc =  0.019480174744884376\n"
     ]
    }
   ],
   "source": [
    "for deg in range (0,14):\n",
    "    meanacc,stdacc = evalutate_stability(y_3,tx_3,1,deg)\n",
    "    print(\"for deg \", deg, \" : mean acc = \", meanacc, \" std acc = \",stdacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best results for least squares\n",
    "#batch 1 : deg = 8   avg acc = 0.8450440396356722   std acc = 0.0003718353247391593\n",
    "#batch 2 : deg = 12  avg acc = 0.8062819190095436   std acc = 0.00014765868113824493\n",
    "#batch 3 : deg = 12  avg acc = 0.8368927488282327   std acc = 0.009791875569386417\n",
    "#overall average acc = 0.8294062358244828   overall std acc = 0.003437123191754607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters with ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_rg(y, x, k_indices, k , lambda_, degree):\n",
    "    loss_te = np.array([])\n",
    "    loss_tr = np.array([])\n",
    "    acc_te = np.array([]) \n",
    "    acc_tr = np.array([]) \n",
    "    #print(x.shape)\n",
    "    for i in range(k):\n",
    "        sub = np.delete(k_indices,i,axis=0).flatten()\n",
    "        x_train = x[sub]\n",
    "        y_train = y[sub]\n",
    "        x_test = x[k_indices[i]]\n",
    "        y_test = y[k_indices[i]]\n",
    "        \n",
    "        x_train = expand_with_pairwise_products(x_train,degree)\n",
    "        x_test = expand_with_pairwise_products(x_test,degree)\n",
    "        \n",
    "        #x_train = np.append(x_train,np.cos(x_train),axis=1)\n",
    "        #x_train = np.append(x_train,np.sin(x_train),axis=1)\n",
    "        #x_test = np.append(x_test,np.cos(x_test),axis=1)\n",
    "        #x_test = np.append(x_test,np.sin(x_test),axis=1)\n",
    "\n",
    "        w,loss_train = imp.ridge_regression(y_train, x_train,lambda_)\n",
    "        acc_train = compute_accuracy(y_train,x_train,w)\n",
    "        acc_test = compute_accuracy(y_test,x_test,w)\n",
    "        loss_test = imp.compute_loss(y_test, x_test, w)\n",
    "        loss_tr = np.append(loss_tr,loss_train)\n",
    "        loss_te= np.append(loss_te,loss_test)\n",
    "        acc_tr = np.append(acc_tr,acc_train)\n",
    "        acc_te = np.append(acc_te,acc_test)\n",
    "    \n",
    "    return np.mean(loss_tr),np.mean(loss_te),np.mean(acc_tr), np.mean(acc_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_lambda(y,x, degree):\n",
    "    seed = 12\n",
    "    k_fold = 5\n",
    "    lambdas = np.logspace(-4, 0, 40)\n",
    "    best_lambda_tr = 0\n",
    "    best_lambda_te = 0\n",
    "    best_acc_tr = 0\n",
    "    best_acc_te = 0\n",
    "    val_l_tr = (0,0,0,0)\n",
    "    val_l_te = (0,0,0,0)\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    # define lists to store the loss and accuracy of training data and test data\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    accuracy_tr = []\n",
    "    accuracy_te = [] \n",
    "    # cross validation\n",
    "    for lambda_ in lambdas:\n",
    "        rmse_tr_tmp = []\n",
    "        rmse_te_tmp = []\n",
    "        acc_tr_tmp = []\n",
    "        acc_te_tmp = []\n",
    "        for k in range(k_fold-1):\n",
    "            loss_tr, loss_te,acc_tr,acc_te = cross_validation_rg(y, x, k_indices, k+1, lambda_, degree)\n",
    "            if(acc_tr>best_acc_tr):\n",
    "                best_acc_tr = acc_tr\n",
    "                best_lambda_tr = lambda_\n",
    "                val_l_tr=(loss_tr,loss_te,acc_tr,acc_te)\n",
    "            if(acc_te>best_acc_te):\n",
    "                best_acc_te = acc_te\n",
    "                best_lambda_te = lambda_\n",
    "                val_l_te=(loss_tr,loss_te,acc_tr,acc_te)\n",
    "            rmse_tr_tmp.append(loss_tr)\n",
    "            rmse_te_tmp.append(loss_te)\n",
    "            acc_tr_tmp.append(acc_tr)\n",
    "            acc_te_tmp.append(acc_te)\n",
    "            #print(\"rmse_tr_temp = \",rmse_tr_tmp)\n",
    "        rmse_tr.append(np.mean(rmse_tr_tmp))\n",
    "        rmse_te.append(np.mean(rmse_te_tmp))\n",
    "        accuracy_tr.append(np.mean(acc_tr_tmp))\n",
    "        accuracy_te.append(np.mean(acc_te_tmp))\n",
    "    #cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "    return (best_lambda_te,val_l_te)  \n",
    "    #return (lambdas, rmse_tr,rmse_te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_overall_param():\n",
    "    for deg in range(8):\n",
    "        best_lambda1,loss_acc_1 = find_best_lambda(y_1,tx_1,deg)\n",
    "        print(\"For batch \" + str(1) +\" and degree : \" + str(deg) + \" The best Test (lambda,(losstr,losste,acctr,accte)) : \"+ str((best_lambda1,loss_acc_1)))\n",
    "    \n",
    "    for deg in range(8):\n",
    "        best_lambda2,loss_acc_2 = find_best_lambda(y_2,tx_2,deg)\n",
    "        print(\"For batch \" + str(2) +\" and degree : \" + str(deg) + \" The best Test (lambda,(losstr,losste,acctr,accte)) : \"+ str((best_lambda2,loss_acc_2)))\n",
    "    \n",
    "    for deg in range(8):\n",
    "        best_lambda3,loss_acc_3 = find_best_lambda(y_3,tx_3,deg)\n",
    "        print(\"For batch \" + str(3) +\" and degree : \" + str(deg) + \" The best Test (lambda,(losstr,losste,acctr,accte)) : \"+ str((best_lambda3,loss_acc_3)))\n",
    "        \n",
    "    return (best_lambda1,loss_acc_1),(best_lambda2,loss_acc_2),(best_lambda3,loss_acc_3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 1 and degree : 0 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001603718743751331, (0.30029315711432913, 0.30555205116348055, 0.7961821889700731, 0.7954283855469924))\n",
      "For batch 1 and degree : 1 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0002030917620904735, (0.2388037549936008, 0.24187571795288057, 0.8330497447702931, 0.8323240916825143))\n",
      "For batch 1 and degree : 2 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.00012663801734674035, (0.2366960779033006, 0.23970574044351156, 0.8342664648183366, 0.8334000600540485))\n",
      "For batch 1 and degree : 3 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0005223345074266843, (0.23388532876818713, 0.7602697967947677, 0.8362995445901311, 0.8357897107396658))\n",
      "For batch 1 and degree : 4 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001, (0.2315874496225282, 0.24314710727620556, 0.8395118106295666, 0.8387548793914523))\n",
      "For batch 1 and degree : 5 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001, (0.22934022558531775, 0.4487383610616935, 0.8414573115804225, 0.8408067260534481))\n",
      "For batch 1 and degree : 6 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.00012663801734674035, (0.228940696079086, 0.30013770720377964, 0.8424144229806827, 0.8417075367831048))\n",
      "For batch 1 and degree : 7 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0004124626382901352, (0.22680842055372247, 1.5701176846727192, 0.8437155940346313, 0.8428085276749074))\n",
      "For batch 2 and degree : 0 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.011253355826007646, (0.4093171171682862, 0.4115166484672308, 0.6710165720918235, 0.6715566159401599))\n",
      "For batch 2 and degree : 1 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.03665241237079626, (0.3454519283746167, 0.3477835707544359, 0.7531677198865101, 0.7525148310549394))\n",
      "For batch 2 and degree : 2 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.018047217668271703, (0.32551492162513096, 0.3242209464794471, 0.7722627031209698, 0.775406241939644))\n",
      "For batch 2 and degree : 3 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.046415888336127774, (0.3234196289772558, 0.3208286942151171, 0.7769054681454733, 0.7805003868970853))\n",
      "For batch 2 and degree : 4 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.003455107294592218, (0.314141507444895, 0.31159162095283766, 0.7841114263605881, 0.7890121227753417))\n",
      "For batch 2 and degree : 5 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.014251026703029978, (0.31292378476829597, 0.3107445186588185, 0.7866101367036369, 0.7903017797265928))\n",
      "For batch 2 and degree : 6 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.014251026703029978, (0.31152104103506056, 0.3090122229843221, 0.7865778952798556, 0.7924297136961568))\n",
      "For batch 2 and degree : 7 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.008886238162743407, (0.30483956393233613, 0.30271105268090254, 0.7927682486458602, 0.7959117874645344))\n",
      "For batch 3 and degree : 0 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.004375479375074184, (0.3670121913467768, 0.36873342915266627, 0.7338365039977943, 0.7366280672732286))\n",
      "For batch 3 and degree : 1 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001603718743751331, (0.3080089240737262, 0.3101748113530609, 0.7892714364488558, 0.7921146953405018))\n",
      "For batch 3 and degree : 2 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0013433993325989001, (0.3032348205481079, 0.30504961322375007, 0.7937000275709953, 0.7952164323132065))\n",
      "For batch 3 and degree : 3 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0008376776400682916, (0.29092702864358067, 0.2948865505980593, 0.8084849738075545, 0.8091397849462365))\n",
      "For batch 3 and degree : 4 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.008886238162743407, (0.2853692286489129, 0.2873816334171238, 0.8157912875654811, 0.8174800110283982))\n",
      "For batch 3 and degree : 5 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0006614740641230146, (0.28201483986499093, 0.2845519060515579, 0.8176867934932451, 0.8204438930245382))\n",
      "For batch 3 and degree : 6 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001, (0.2788235983646754, 0.28245641016166345, 0.8191342707471739, 0.8217535153019024))\n",
      "For batch 3 and degree : 7 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.00025719138090593444, (0.26835061634272156, 0.271651836448498, 0.8253205128205128, 0.8298180314309347))\n"
     ]
    }
   ],
   "source": [
    "(best_lambda1,loss_acc_1),(best_lambda2,loss_acc_2),(best_lambda3,loss_acc_3) = find_best_overall_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.0004124626382901352,\n",
       "  (0.22680842055372247,\n",
       "   1.5701176846727192,\n",
       "   0.8437155940346313,\n",
       "   0.8428085276749074)),\n",
       " (0.008886238162743407,\n",
       "  (0.30483956393233613,\n",
       "   0.30271105268090254,\n",
       "   0.7927682486458602,\n",
       "   0.7959117874645344)),\n",
       " (0.00025719138090593444,\n",
       "  (0.26835061634272156,\n",
       "   0.271651836448498,\n",
       "   0.8253205128205128,\n",
       "   0.8298180314309347)))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(best_lambda1,loss_acc_1),(best_lambda2,loss_acc_2),(best_lambda3,loss_acc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_overall_param2():\n",
    "    for deg in range(8,15):\n",
    "        best_lambda1,loss_acc_1 = find_best_lambda(y_1,tx_1,deg)\n",
    "        print(\"For batch \" + str(1) +\" and degree \" + str(deg) + \" The best Test (lambda,(losstr,losste,acctr,accte)) : \"+ str((best_lambda1,loss_acc_1)))\n",
    "    \n",
    "    for deg in range(8,15):\n",
    "        best_lambda2,loss_acc_2 = find_best_lambda(y_2,tx_2,deg)\n",
    "        print(\"For batch \" + str(2) +\" and degree \" + str(deg) + \" The best Test (lambda,(losstr,losste,acctr,accte)) : \"+ str((best_lambda2,loss_acc_2)))\n",
    "    \n",
    "    for deg in range(8,15):\n",
    "        best_lambda3,loss_acc_3 = find_best_lambda(y_3,tx_3,deg)\n",
    "        print(\"For batch \" + str(3) +\" and degree \" + str(deg) + \" The best Test (lambda,(losstr,losste,acctr,accte)) : \"+ str((best_lambda3,loss_acc_3)))\n",
    "        \n",
    "    return (best_lambda1,loss_acc_1),(best_lambda2,loss_acc_2),(best_lambda3,loss_acc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 1 and degree 8 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001603718743751331, (0.22460794609718232, 7.8884319405228185, 0.8457924632168952, 0.8455359823841457))\n",
      "For batch 1 and degree 9 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001603718743751331, (0.2239903660605052, 0.8375191665376706, 0.8464367931138024, 0.84618656791112))\n",
      "For batch 1 and degree 10 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001, (0.2236858067487893, 42.294082877087355, 0.8464868381543389, 0.8463367030327296))\n",
      "For batch 1 and degree 11 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.003455107294592218, (0.22677148719526288, 393516175822863.2, 0.8461959513562205, 0.845248223401061))\n",
      "For batch 1 and degree 12 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001603718743751331, (0.22300894328367965, 18898.77006311145, 0.8474189270343309, 0.8467370633570213))\n",
      "For batch 1 and degree 13 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.00012663801734674035, (0.22443450951418667, 47437.187005466796, 0.8467308077269543, 0.8458112301070964))\n",
      "For batch 1 and degree 14 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0008376776400682916, (0.2257608568490982, 7.835845357609034e+19, 0.8461532045507623, 0.844977146098155))\n",
      "For batch 2 and degree 8 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0002030917620904735, (0.2948903309410026, 0.2924418395292841, 0.801924812999742, 0.8028114521537271))\n",
      "For batch 2 and degree 9 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0006614740641230146, (0.2908343325133293, 0.28749151508804227, 0.8049555068351818, 0.8061645602269796))\n",
      "For batch 2 and degree 10 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0013433993325989001, (0.2905617341897881, 0.2877751986420653, 0.8056164560226979, 0.8057776631416044))\n",
      "For batch 2 and degree 11 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.003455107294592218, (0.289541600095466, 0.28626244338261103, 0.8055036110394636, 0.8063580087696672))\n",
      "For batch 2 and degree 12 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0004124626382901352, (0.28524502189773177, 0.28338361914579796, 0.8078572349754966, 0.8075831828733557))\n",
      "For batch 2 and degree 13 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001603718743751331, (0.2839261486560952, 0.29267382858090524, 0.8083408563322156, 0.8090018055197318))\n",
      "For batch 2 and degree 14 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0001603718743751331, (0.28465606962373907, 0.2983496910128201, 0.808502063451122, 0.808099045653856))\n",
      "For batch 3 and degree 8 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.00025719138090593444, (0.25676983139223225, 0.26112659175686237, 0.8350909842845327, 0.8376068376068376))\n",
      "For batch 3 and degree 9 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.00012663801734674035, (0.2519759347649514, 0.2564809024434003, 0.8386752136752137, 0.8412599944858009))\n",
      "For batch 3 and degree 10 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0004124626382901352, (0.25178127559571073, 0.335508513375897, 0.8386235180590019, 0.8407775020678246))\n",
      "For batch 3 and degree 11 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.00012663801734674035, (0.24997019198710618, 0.33243019980662303, 0.8399503722084367, 0.8422249793217536))\n",
      "For batch 3 and degree 12 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0008376776400682916, (0.24592848812007712, 1.1216834050028173, 0.8422594430658947, 0.8447063688999172))\n",
      "For batch 3 and degree 13 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.002154434690031882, (0.24476609720368717, 4.589155691900101, 0.8428453267162944, 0.8451199338296113))\n",
      "For batch 3 and degree 14 The best Test (lambda,(losstr,losste,acctr,accte)) : (0.0010608183551394483, (0.24481631990115676, 1382.134407950883, 0.8436379928315412, 0.8427074717397298))\n"
     ]
    }
   ],
   "source": [
    "(best_lambda4,loss_acc_4),(best_lambda5,loss_acc_5),(best_lambda6,loss_acc_6) = find_best_overall_param2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results for ridge regression\n",
    "#1 lambda = 0.0001                 degree = 10  mean acc = 0.8467370633570213   std acc = 0.0007417655852458556 \n",
    "#2 lambda = 0.0004124626382901352  degree = 12  mean acc = 0.808099045653856    std acc = 0.00018879961116990187\n",
    "#3 lambda = 0.0008376776400682916  degree = 12  mean acc = 0.8451199338296113   std acc = 0.000357086967451429\n",
    "#overall avg acc = 0.8333186809468295   overall std acc = 0.00042921738795572887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for submission :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_1= expand_with_pairwise_products(tx_1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_2= expand_with_pairwise_products(tx_2,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_3= expand_with_pairwise_products(tx_3,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 , l1 = imp.ridge_regression(y_1,tx_1, 0.0001)\n",
    "w2 , l2 = imp.ridge_regression(y_2,tx_2,0.0004124626382901352)\n",
    "w3 , l3 = imp.ridge_regression(y_3,tx_3,0.0008376776400682916)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_1 = expand_with_pairwise_products(xtest_1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_2 = expand_with_pairwise_products(xtest_2,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_3 = expand_with_pairwise_products(xtest_3,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_lg(y, x, degree):\n",
    "    gamma = 0.001\n",
    "    max_iter = 1000\n",
    "    k_fold = 5 \n",
    "    seed = 12\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    loss_te = np.array([])\n",
    "    loss_tr = np.array([])\n",
    "    acc_te = np.array([]) \n",
    "    acc_tr = np.array([]) \n",
    "    for i in range(k_fold):\n",
    "        sub = np.delete(k_indices,i,axis=0).flatten()\n",
    "        x_train = x[sub]\n",
    "        y_train = y[sub]\n",
    "        x_test = x[k_indices[i]]\n",
    "        y_test = y[k_indices[i]]\n",
    "\n",
    "        #print('train expanded',x_train.shape)\n",
    "        #print('test expanded',x_test.shape)\n",
    "        \n",
    "        x_train = expand_with_pairwise_products(x_train,degree)\n",
    "        initial_w = np.zeros((x_train.shape[1], 1))\n",
    "        x_test = expand_with_pairwise_products(x_test,degree)\n",
    "        \n",
    "        #x_train = np.append(x_train,np.cos(x_train),axis=1)\n",
    "        #x_train = np.append(x_train,np.sin(x_train),axis=1)\n",
    "        #x_train = add_bias(x_train)\n",
    "        #x_test = np.append(x_test,np.cos(x_test),axis=1)\n",
    "        #x_test = np.append(x_test,np.sin(x_test),axis=1)\n",
    "        \n",
    "        #x_test = add_bias(x_test)\n",
    "\n",
    "        w,loss_train = imp.logistic_regression(y_train, x_train,initial_w,max_iter,gamma) \n",
    "        acc_train = compute_accuracy(y_train,x_train,w)\n",
    "        acc_test = compute_accuracy(y_test,x_test,w)\n",
    "        loss_test = imp.calculate_loss_likelihood(w, x_test, y_test)\n",
    "        loss_tr = np.append(loss_tr,loss_train)\n",
    "        loss_te= np.append(loss_te,loss_test)\n",
    "        acc_tr = np.append(acc_tr,acc_train)\n",
    "        acc_te = np.append(acc_te,acc_test)\n",
    "    \n",
    "    return degree, (np.mean(loss_tr),np.mean(loss_te),np.mean(acc_tr), np.mean(acc_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 1 and degree : 0 The best Test (losstr,losste,acctr,accte) : (0.5480943738635943, 0.5600502352130678, 0.7448454667027369, 0.7448503653287959)\n",
      "For batch 1 and degree : 1 The best Test (losstr,losste,acctr,accte) : (0.541673991069666, 0.5602275491873472, 0.7448454667027369, 0.7448503653287959)\n",
      "For batch 1 and degree : 2 The best Test (losstr,losste,acctr,accte) : (0.30277700698907173, 0.3239469594277581, 0.7448503653287959, 0.7448503653287959)\n",
      "For batch 1 and degree : 3 The best Test (losstr,losste,acctr,accte) : (-0.20122413417092783, -0.321203994464999, 0.7446923516571781, 0.7446830082215621)\n",
      "For batch 1 and degree : 4 The best Test (losstr,losste,acctr,accte) : (-163.4041168417742, -27.956285795536083, 0.5950883869499164, 0.595216144935807)\n",
      "For batch 1 and degree : 5 The best Test (losstr,losste,acctr,accte) : (-398907.33930783416, 362518.2215824526, 0.543870777802214, 0.5429434824842507)\n",
      "For batch 2 and degree : 0 The best Test (losstr,losste,acctr,accte) : (0.6284195800085334, 0.6310785173193303, 0.6426489553778695, 0.6426489553778695)\n",
      "For batch 2 and degree : 1 The best Test (losstr,losste,acctr,accte) : (0.6231095770999839, 0.6310048336780893, 0.6426489553778695, 0.6426489553778695)\n",
      "For batch 2 and degree : 2 The best Test (losstr,losste,acctr,accte) : (0.433133871275276, 0.4500662537131069, 0.6426489553778695, 0.6426489553778695)\n",
      "For batch 2 and degree : 3 The best Test (losstr,losste,acctr,accte) : (0.09864611433613205, 0.30258366458981917, 0.6426489553778695, 0.6426489553778695)\n",
      "For batch 2 and degree : 4 The best Test (losstr,losste,acctr,accte) : (-16.96318092025728, -6.309904587057166, 0.6417868900183745, 0.6417374104100896)\n",
      "For batch 2 and degree : 5 The best Test (losstr,losste,acctr,accte) : (-1482.0927743595257, -538.9193442121057, 0.579150272910305, 0.5792146734287226)\n",
      "For batch 2 and degree : 6 The best Test (losstr,losste,acctr,accte) : (-194459.77258483443, -68268.3945820141, 0.6283731938898269, 0.6285427927602776)\n",
      "For batch 2 and degree : 7 The best Test (losstr,losste,acctr,accte) : (-32700682.384810198, -10471764.013575729, 0.5015883240124543, 0.5012153677877424)\n",
      "For batch 3 and degree : 0 The best Test (losstr,losste,acctr,accte) : (0.6173208776298847, 0.6273223089728928, 0.5524676040805073, 0.5524676040805073)\n",
      "For batch 3 and degree : 1 The best Test (losstr,losste,acctr,accte) : (0.6052009722532619, 0.6273890755898448, 0.5524676040805073, 0.5524676040805073)\n",
      "For batch 3 and degree : 2 The best Test (losstr,losste,acctr,accte) : (0.4362296361441283, 0.48707736218880093, 0.5524676040805073, 0.5524676040805073)\n",
      "For batch 3 and degree : 3 The best Test (losstr,losste,acctr,accte) : (-0.20809370446094727, 0.3749356481971794, 0.5510276344734059, 0.5510251932915291)\n",
      "For batch 3 and degree : 4 The best Test (losstr,losste,acctr,accte) : (-35.29178609301617, -4.785831243731684, 0.5501336018825812, 0.5501325642644781)\n",
      "For batch 3 and degree : 5 The best Test (losstr,losste,acctr,accte) : (-3668.7016540138547, -489.2564985431133, 0.5219701296021119, 0.5219823994124269)\n",
      "For batch 3 and degree : 6 The best Test (losstr,losste,acctr,accte) : (-578255.7332699712, -70476.58393029662, 0.5475411593740358, 0.5475274225741155)\n",
      "For batch 3 and degree : 7 The best Test (losstr,losste,acctr,accte) : (-127936417.13130987, -13496342.088405114, 0.5040679336696356, 0.5041697158575944)\n"
     ]
    }
   ],
   "source": [
    "for deg in range(6):\n",
    "    degree1,loss_acc_1 = cross_validation_lg(y_1,tx_1, deg)\n",
    "    print(\"For batch \" + str(1) +\" and degree : \" + str(deg) + \" The best Test (losstr,losste,acctr,accte) : \"+ str(loss_acc_1))           \n",
    "for deg in range(8):\n",
    "    degree2,loss_acc_2 = cross_validation_lg(y_2,tx_2,deg)\n",
    "    print(\"For batch \" + str(2) +\" and degree : \" + str(deg) + \" The best Test (losstr,losste,acctr,accte) : \"+ str(loss_acc_2))\n",
    "for deg in range(8):\n",
    "    degree3,loss_acc_3 = cross_validation_lg(y_3,tx_3,deg)\n",
    "    print(\"For batch \" + str(3) +\" and degree : \" + str(deg) + \" The best Test (losstr,losste,acctr,accte) : \"+ str(loss_acc_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result for logistic regression\n",
    "#1 degree = 2  acc = 0.7448503653287959   \n",
    "#2 degree = 0  acc = 0.6426489553778695    \n",
    "#3 degree = 1  acc = 0.5524676040805073  \n",
    "#overall acc = 0.6466556415957242"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = predict_labels(w1, xtest_1)\n",
    "y_pred2 = predict_labels(w2, xtest_2)\n",
    "y_pred3 = predict_labels(w3, xtest_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((y_pred1,y_pred2))\n",
    "y = np.concatenate((y,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.concatenate((ids_1,ids_2))\n",
    "ids = np.concatenate((ids,ids_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-9bab8864518e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../resources/gd.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcreate_csv_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/ML/scripts/proj1_helpers.py\u001b[0m in \u001b[0;36mcreate_csv_submission\u001b[0;34m(ids, y_pred, name)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../resources/gd.csv'\n",
    "create_csv_submission(ids, y,OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1fd3f6379285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "from run import *\n",
    "run.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
